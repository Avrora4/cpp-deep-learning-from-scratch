{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Sample code asscociated with CUDA-Kernel\n",
        "### General\n",
        "- This code is the sample code associated with CUDA-Kernel for google colabratory\n",
        "- Even if you don't have a GPU environment, you can easily verify it by running the following notebook on google colaboratory.\n",
        "\n",
        "### Environment\n",
        "- Comfirm to run the code in below environment at 2025/10/21\n",
        "  - Runtime Type : Python 3\n",
        "  - Hardware Accelarator : T4 GPU\n",
        "  - Runtime Version : latest at 2025/10/21"
      ],
      "metadata": {
        "id": "zikqniU_r4Rd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXp01VVvCoY4",
        "outputId": "e055d0a2-bbe2-4131-d21f-eb63f124afad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_kernel.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cuda_kernel.cu\n",
        "// Kernel denition\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define CUDA_CHECK(call)\\\n",
        "    do\\\n",
        "    {\\\n",
        "        cudaError_t err = (call);\\\n",
        "        if(err != cudaSuccess)\\\n",
        "        {\\\n",
        "            fprintf(stderr, \"CUDA error %s:%d: %s\\n\", __FILE__, __LINE__,cudaGetErrorString(err));\\\n",
        "            exit(EXIT_FAILURE);\\\n",
        "        }\\\n",
        "    } while (0)\\\n",
        "\n",
        "__global__ void MatAdd(const float *A, const float *B, float *C, int N)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(row< N && col < N)\n",
        "    {\n",
        "        int idx = row * N + col;\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "    // C[i][j] = A[i][j] + B[i][j];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // float *A, *B, *C;\n",
        "    int N = 16;\n",
        "    size_t bytes = (size_t)N * N * sizeof(float);\n",
        "\n",
        "    float *hA = (float*)malloc(bytes);\n",
        "    float *hB = (float*)malloc(bytes);\n",
        "    float *hC = (float*)malloc(bytes);\n",
        "    if(!hA || !hB || !hC)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    for (int i = 0; i < N * N; ++i)\n",
        "    {\n",
        "        hA[i] = 1.0f * i;\n",
        "        hB[i] = 2.0f * i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on device\n",
        "    /*\n",
        "    cudaMalloc((void**)&A, N*N*sizeof(float));\n",
        "    cudaMalloc((void**)&B, N*N*sizeof(float));\n",
        "    cudaMalloc((void**)&C, N*N*sizeof(float));\n",
        "    float *a = malloc(N*N*sizeof(float));\n",
        "    float *b = malloc(N*N*sizeof(float));\n",
        "    float *c = malloc(N*N*sizeof(float));\n",
        "    */\n",
        "\n",
        "    float *dA = NULL;\n",
        "    float *dB = NULL;\n",
        "    float *dC = NULL;\n",
        "    CUDA_CHECK(cudaMalloc((void**)&dA, bytes));\n",
        "    CUDA_CHECK(cudaMalloc((void**)&dB, bytes));\n",
        "    CUDA_CHECK(cudaMalloc((void**)&dC, bytes));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(dA, hA, bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(dB, hB, bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "\n",
        "    // cudaMemcpy(A, a, N * N * sizeof(*A), cudaMemcpyHostToDevice);\n",
        "    // cudaMemcpy(B, b, N * N * sizeof(*B), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // kernel invocation with one block of N * N * 1 threads\n",
        "    // int numBlocks = 1;\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "    MatAdd<<<numBlocks, threadsPerBlock>>>(dA, dB, dC, N);\n",
        "\n",
        "    // runtime error check\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // Device -> Host copy\n",
        "    CUDA_CHECK(cudaMemcpy(hC, dC, bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // results (Header 4 * 4)\n",
        "    for (int r = 0; r < 4 && r < N; ++r)\n",
        "    {\n",
        "        for (int c = 0; c < 4 && c < N; ++c)\n",
        "        {\n",
        "            printf(\"%8.1f \", hC[r * N + c]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // cudaMecpy(c, C, N * N * sizeof(*c), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // free device memory\n",
        "    CUDA_CHECK(cudaFree(dA));\n",
        "    CUDA_CHECK(cudaFree(dB));\n",
        "    CUDA_CHECK(cudaFree(dC));\n",
        "    free(hA);\n",
        "    free(hB);\n",
        "    free(hC);\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cuda_kernel.cu -arch=sm_75 -o cuda_kernel"
      ],
      "metadata": {
        "id": "QEJv60uoDECu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./cuda_kernel"
      ],
      "metadata": {
        "id": "Z_5K-oyZDR0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7fe511-fb59-43a3-d8b6-634ce95bed9a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0.0      3.0      6.0      9.0 \n",
            "    48.0     51.0     54.0     57.0 \n",
            "    96.0     99.0    102.0    105.0 \n",
            "   144.0    147.0    150.0    153.0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MNY-OLg5n4Rh"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}